{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import AdamW\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras import backend as K\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nimport cv2\nimport os\nimport random\n\n# --- KONFIGURASI PATH KHUSUS KAGGLE ---\n# Dataset di Kaggle biasanya ada di path ini\n# Kita cek apakah foldernya double nesting atau tidak\nbase_path = '/kaggle/input/chest-xray-pneumonia/chest_xray'\n\nif os.path.exists(os.path.join(base_path, 'chest_xray')):\n    print(\"Mendeteksi struktur folder ganda...\")\n    base_dir = os.path.join(base_path, 'chest_xray')\nelse:\n    base_dir = base_path\n\ntrain_dir = os.path.join(base_dir, 'train')\ntest_dir = os.path.join(base_dir, 'test')\n# Kita abaikan folder 'val' bawaan dataset karena isinya terlalu sedikit (cuma 16 gambar)\n# Kita akan buat validasi sendiri dari folder train\n\nprint(f\"Train Dir: {train_dir}\")\nprint(f\"Test Dir:  {test_dir}\")\n\n# Parameter\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 25 # Agak lama karena learning rate kecil (fine-tuning)\n\nprint(\"GPU Available:\", tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 2: DATA LOADING (EFFICIENTNET VERSION) ---\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\n# Hapus rescale=1./255, ganti dengan preprocessing_function bawaan model\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input, # Trik agar akurasi maksimal\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    validation_split=0.2\n)\n\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\nprint(\"Setup Generators EfficientNet...\")\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training',\n    shuffle=True\n)\n\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 3: MODEL ARCHITECTURE (EFFICIENTNET-B0) ---\n\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras import backend as K\n\ndef focal_loss(gamma=2., alpha=0.25):\n    def binary_focal_loss(y_true, y_pred):\n        y_true = tf.cast(y_true, tf.float32)\n        alpha_t = y_true * alpha + (K.ones_like(y_true) - y_true) * (1 - alpha)\n        p_t = y_true * y_pred + (K.ones_like(y_true) - y_true) * (1 - y_pred) + K.epsilon()\n        focal_loss = - alpha_t * K.pow((K.ones_like(y_true) - p_t), gamma) * K.log(p_t)\n        return K.mean(focal_loss)\n    return binary_focal_loss\n\ndef build_model_efficientnet():\n    # 1. Load EfficientNetB0\n    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n    \n    # 2. FINE TUNING\n    base_model.trainable = True\n    \n    # EfficientNetB0 punya sekitar 230+ layers\n    # Kita freeze layer awal, sisakan 40 layer terakhir\n    for layer in base_model.layers[:-40]:\n        layer.trainable = False\n\n    # 3. Custom Head\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x) \n    predictions = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(inputs=base_model.input, outputs=predictions)\n    \n    # 4. Compile (Tetap pakai LR kecil)\n    model.compile(optimizer=AdamW(learning_rate=1e-5, weight_decay=1e-4),\n                  loss=focal_loss(gamma=2.0, alpha=0.25),\n                  metrics=['accuracy', tf.keras.metrics.Recall(name='sensitivity'), tf.keras.metrics.AUC(name='auc')])\n    \n    return model\n\nmodel = build_model_efficientnet()\nprint(\"Model diganti menjadi: EFFICIENTNET-B0\")\n# model.summary() # Boleh di-uncomment kalau mau lihat strukturnya","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 4: TRAINING (NEW FILENAME) ---\n\n# Nama file dibedakan\ncheckpoint_path = '/kaggle/working/model_EFFICIENTNET_best.keras'\nfinal_model_path = '/kaggle/working/model_EFFICIENTNET_final.keras'\n\ncallbacks = [\n    ModelCheckpoint(checkpoint_path, monitor='val_auc', save_best_only=True, mode='max', verbose=1),\n    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1)\n]\n\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS, \n    validation_data=val_generator,\n    callbacks=callbacks\n)\n\nmodel.save(final_model_path)\nprint(f\"Model disimpan dengan nama: {final_model_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- EVALUATION & METRICS ---\n\n# Prediksi Data Test\npredictions = model.predict(test_generator)\ny_pred_binary = (predictions > 0.5).astype(int).flatten()\ny_true = test_generator.classes\n\n# Confusion Matrix\ntn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\naccuracy = (tp + tn) / (tp + tn + fp + fn)\nsensitivity = tp / (tp + fn)\nspecificity = tn / (tn + fp)\nroc_auc = auc(*roc_curve(y_true, predictions)[:2])\n\nprint(f\"\\nAKURASI: {accuracy:.4f}\")\nprint(f\"SENSITIVITAS (Recall): {sensitivity:.4f}\")\nprint(f\"SPESIFITAS: {specificity:.4f}\")\nprint(f\"ROC-AUC: {roc_auc:.4f}\")\n\n# Visualisasi Grafik\nplt.figure(figsize=(18, 5))\n\n# Plot Loss & Acc\nplt.subplot(1, 3, 1)\nplt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.title('Training Accuracy')\nplt.legend()\n\n# Confusion Matrix\nplt.subplot(1, 3, 2)\nsns.heatmap([[tn, fp], [fn, tp]], annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Normal', 'Pneumonia'], yticklabels=['Normal', 'Pneumonia'])\nplt.title('Confusion Matrix')\n\n# ROC Curve\nfpr, tpr, _ = roc_curve(y_true, predictions)\nplt.subplot(1, 3, 3)\nplt.plot(fpr, tpr, color='orange', lw=2, label=f'AUC = {roc_auc:.2f}')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.title('ROC Curve')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- LOAD MODEL TERBAIK SECARA MANUAL ---\nfrom tensorflow.keras.models import load_model\n\n# Lokasi file terbaik yang baru saja kita simpan\nbest_model_path = '/kaggle/working/model_EFFICIENTNET_final.keras'\n\nprint(f\"Sedang meload model terbaik dari: {best_model_path} ...\")\n\n# PENTING: Kita pakai compile=False karena kita cuma mau Prediksi (Predict), \n# bukan mau lanjut training. Ini menghindari error ribet soal 'focal loss'.\nmodel = load_model(best_model_path, compile=False)\n\nprint(\"âœ… Model BERHASIL diload! Sekarang model di memori adalah versi TERBAIK.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 7: GRAD-CAM FUNCTION (OPTIMIZED & CLEANED) ---\nimport cv2\nimport numpy as np\nimport tensorflow as tf\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # 1. Buat model gradien\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # 2. Rekam operasi gradien\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # 3. Hitung gradien\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    \n    # 4. Global Average Pooling (Rata-rata gradien)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # 5. Kalikan feature map dengan bobot gradien\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # 6. Normalisasi (ReLU & Scaling)\n    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10) # Tambah epsilon biar gak error bagi 0\n    return heatmap.numpy()\n\ndef overlay_heatmap(img_path, heatmap, alpha=0.4, threshold=0.3):\n    \"\"\"\n    Args:\n        threshold (float): Nilai 0.0 - 1.0. \n                           Area heatmap di bawah nilai ini akan dibuang (dihitamkan).\n                           Berguna untuk menghilangkan noise/biru-biru di background.\n    \"\"\"\n    # 1. Load Gambar Asli\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, IMG_SIZE) # Pastikan ukuran sama (224, 224)\n    \n    # 2. Resize Heatmap agar sama persis dengan gambar asli\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n    \n    # --- FITUR BARU: CLEAN NOISE (THRESHOLDING) ---\n    # Buang area yang panasnya kurang dari 30% (0.3)\n    # Ini membuat heatmap lebih fokus, tidak melebar ke mana-mana\n    heatmap[heatmap < threshold] = 0 \n    # ----------------------------------------------\n    \n    # 3. Ubah ke format 8-bit (0-255)\n    heatmap_uint8 = np.uint8(255 * heatmap)\n    \n    # 4. Beri Warna (JET: Biru=Dingin, Merah=Panas)\n    heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n    \n    # 5. Trik Visualisasi: \n    # Di colormap JET, nilai 0 (hitam) itu warnanya Biru Tua.\n    # Kita tidak mau background jadi biru semua.\n    # Jadi, area yang tadi kita buang (di bawah threshold), kita hitamkan kembali warnanya.\n    heatmap_colored[heatmap < threshold] = 0\n    \n    # 6. Gabungkan (Overlay)\n    superimposed_img = heatmap_colored * alpha + img\n    \n    # Pastikan tidak ada nilai pixel > 255\n    superimposed_img = np.clip(superimposed_img, 0, 255).astype('uint8')\n    \n    return img, superimposed_img","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 8: TEST PREDICTION (REVISED FOR EFFICIENTNET) ---\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\n# Nama layer terakhir EfficientNetB0\nlast_conv_layer_name = \"block5c_add\"\n\n# Ambil sample acak\ntarget_class = random.choice(['PNEUMONIA', 'NORMAL']) \nsample_dir = os.path.join(test_dir, target_class)\nsample_image = random.choice(os.listdir(sample_dir))\nimg_path = os.path.join(sample_dir, sample_image)\n\n# --- BAGIAN PENTING (JANGAN SALAH DISINI) ---\nimg = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\n\n# HAPUS baris: img_array /= 255.0 (JANGAN PAKAI INI UNTUK EFFICIENTNET)\n# GANTI DENGAN INI:\nimg_array = preprocess_input(img_array) \n# ---------------------------------------------\n\n# Prediksi\npreds = model.predict(img_array)\nscore = preds[0][0]\n\nlabel_pred = \"PNEUMONIA\" if score > 0.5 else \"NORMAL\"\nconfidence = score if score > 0.5 else 1 - score\n\nprint(f\"File: {sample_image}\")\nprint(f\"Ground Truth: {target_class}\")\nprint(f\"Prediksi: {label_pred} ({confidence*100:.2f}%)\")\n\n# Grad-CAM\nheatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=0)\noriginal_img, superimposed_img = overlay_heatmap(img_path, heatmap)\n\n# Plot\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 3, 1)\nplt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\nplt.title(f\"Asli: {target_class}\")\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(heatmap, cmap='jet')\nplt.title(\"Heatmap\")\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\nplt.title(f\"Prediksi: {label_pred}\\nConf: {confidence*100:.1f}%\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Validasi Text\nif label_pred == target_class:\n    print(\"âœ… PREDIKSI BENAR\")\nelse:\n    print(\"âŒ PREDIKSI SALAH\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- PART 9 (UPGRADE): APLIKASI WEB DENGAN SLIDER ---\nimport gradio as gr\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\n# Fungsi Prediksi menerima input tambahan: THRESHOLD\ndef predict_image_interactive(image, threshold_slider):\n    if image is None:\n        return None, None\n        \n    # 1. Preprocessing\n    img_array = cv2.resize(image, IMG_SIZE)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n    \n    # 2. Prediksi\n    preds = model.predict(img_array)\n    score = preds[0][0]\n    \n    if score > 0.5:\n        label = \"PNEUMONIA\"\n        conf = score\n    else:\n        label = \"NORMAL\"\n        conf = 1 - score\n        \n    # 3. Buat Grad-CAM\n    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=0)\n    \n    # Resize ke ukuran asli gambar input\n    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n    \n    # --- PROSES SLIDER ---\n    # Gunakan nilai dari Slider Gradio untuk membersihkan heatmap\n    heatmap_clean = heatmap.copy()\n    heatmap_clean[heatmap_clean < threshold_slider] = 0 \n    # ---------------------\n    \n    # Pewarnaan\n    heatmap_uint8 = np.uint8(255 * heatmap_clean)\n    heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n    \n    # Hapus background biru (kembalikan warna asli jika heatmap 0)\n    heatmap_colored[heatmap_clean < threshold_slider] = 0\n    \n    # Overlay\n    superimposed_img = heatmap_colored * 0.4 + image\n    \n    # Fix warna background yang hitam jadi gambar asli\n    mask = heatmap_clean < threshold_slider\n    superimposed_img[mask] = image[mask]\n    \n    superimposed_img = np.clip(superimposed_img, 0, 255).astype('uint8')\n    \n    return {label: float(conf), \"Lawan\": 1-float(conf)}, superimposed_img\n\n# Setup Antarmuka dengan Slider\ninterface = gr.Interface(\n    fn=predict_image_interactive,\n    inputs=[\n        gr.Image(label=\"1. Upload X-Ray\"),\n        gr.Slider(minimum=0.0, maximum=1.0, value=0.3, label=\"2. Sensitivitas Heatmap (Geser untuk filter noise)\")\n    ],\n    outputs=[\n        gr.Label(num_top_classes=2, label=\"Hasil Prediksi\"),\n        gr.Image(label=\"Visualisasi Lokasi Penyakit\")\n    ],\n    title=\"ðŸ¥ Advanced Pneumonia Detector\",\n    description=\"Analisis X-Ray berbasis EfficientNet-B0 dengan Grad-CAM Interaktif.\",\n    # Contoh gambar biar cepat tes (ambil dari folder test)\n    examples=[\n        [os.path.join(test_dir, 'PNEUMONIA', os.listdir(os.path.join(test_dir, 'PNEUMONIA'))[0]), 0.3],\n        [os.path.join(test_dir, 'NORMAL', os.listdir(os.path.join(test_dir, 'NORMAL'))[0]), 0.3]\n    ]\n)\n\ninterface.launch(share=True, debug=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}