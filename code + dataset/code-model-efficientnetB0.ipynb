{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "# --- KONFIGURASI PATH KHUSUS KAGGLE ---\n",
    "# Dataset di Kaggle biasanya ada di path ini\n",
    "# Kita cek apakah foldernya double nesting atau tidak\n",
    "base_path = '/kaggle/input/chest-xray-pneumonia/chest_xray'\n",
    "\n",
    "if os.path.exists(os.path.join(base_path, 'chest_xray')):\n",
    "    print(\"Mendeteksi struktur folder ganda...\")\n",
    "    base_dir = os.path.join(base_path, 'chest_xray')\n",
    "else:\n",
    "    base_dir = base_path\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "# Kita abaikan folder 'val' bawaan dataset karena isinya terlalu sedikit (cuma 16 gambar)\n",
    "# Kita akan buat validasi sendiri dari folder train\n",
    "\n",
    "print(f\"Train Dir: {train_dir}\")\n",
    "print(f\"Test Dir:  {test_dir}\")\n",
    "\n",
    "# Parameter\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25 # Agak lama karena learning rate kecil (fine-tuning)\n",
    "\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- PART 2: DATA LOADING (EFFICIENTNET VERSION) ---\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Hapus rescale=1./255, ganti dengan preprocessing_function bawaan model\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, # Trik agar akurasi maksimal\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "print(\"Setup Generators EfficientNet...\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- PART 3: MODEL ARCHITECTURE (EFFICIENTNET-B0) ---\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def binary_focal_loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_t = y_true * alpha + (K.ones_like(y_true) - y_true) * (1 - alpha)\n",
    "        p_t = y_true * y_pred + (K.ones_like(y_true) - y_true) * (1 - y_pred) + K.epsilon()\n",
    "        focal_loss = - alpha_t * K.pow((K.ones_like(y_true) - p_t), gamma) * K.log(p_t)\n",
    "        return K.mean(focal_loss)\n",
    "    return binary_focal_loss\n",
    "\n",
    "def build_model_efficientnet():\n",
    "    # 1. Load EfficientNetB0\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    \n",
    "    # 2. FINE TUNING\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # EfficientNetB0 punya sekitar 230+ layers\n",
    "    # Kita freeze layer awal, sisakan 40 layer terakhir\n",
    "    for layer in base_model.layers[:-40]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 3. Custom Head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) \n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # 4. Compile (Tetap pakai LR kecil)\n",
    "    model.compile(optimizer=AdamW(learning_rate=1e-5, weight_decay=1e-4),\n",
    "                  loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "                  metrics=['accuracy', tf.keras.metrics.Recall(name='sensitivity'), tf.keras.metrics.AUC(name='auc')])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model_efficientnet()\n",
    "print(\"Model diganti menjadi: EFFICIENTNET-B0\")\n",
    "# model.summary() # Boleh di-uncomment kalau mau lihat strukturnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- PART 4: TRAINING (NEW FILENAME) ---\n",
    "\n",
    "# Nama file dibedakan\n",
    "checkpoint_path = '/kaggle/working/model_EFFICIENTNET_best.keras'\n",
    "final_model_path = '/kaggle/working/model_EFFICIENTNET_final.keras'\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkpoint_path, monitor='val_auc', save_best_only=True, mode='max', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model.save(final_model_path)\n",
    "print(f\"Model disimpan dengan nama: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- EVALUATION & METRICS ---\n",
    "\n",
    "# Prediksi Data Test\n",
    "predictions = model.predict(test_generator)\n",
    "y_pred_binary = (predictions > 0.5).astype(int).flatten()\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "roc_auc = auc(*roc_curve(y_true, predictions)[:2])\n",
    "\n",
    "print(f\"\\nAKURASI: {accuracy:.4f}\")\n",
    "print(f\"SENSITIVITAS (Recall): {sensitivity:.4f}\")\n",
    "print(f\"SPESIFITAS: {specificity:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Visualisasi Grafik\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Plot Loss & Acc\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.heatmap([[tn, fp], [fn, tp]], annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Normal', 'Pneumonia'], yticklabels=['Normal', 'Pneumonia'])\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_true, predictions)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(fpr, tpr, color='orange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- LOAD MODEL TERBAIK SECARA MANUAL ---\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Lokasi file terbaik yang baru saja kita simpan\n",
    "best_model_path = '/kaggle/working/model_EFFICIENTNET_final.keras'\n",
    "\n",
    "print(f\"Sedang meload model terbaik dari: {best_model_path} ...\")\n",
    "\n",
    "# PENTING: Kita pakai compile=False karena kita cuma mau Prediksi (Predict), \n",
    "# bukan mau lanjut training. Ini menghindari error ribet soal 'focal loss'.\n",
    "model = load_model(best_model_path, compile=False)\n",
    "\n",
    "print(\"âœ… Model BERHASIL diload! Sekarang model di memori adalah versi TERBAIK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- PART 7: GRAD-CAM FUNCTION (OPTIMIZED & CLEANED) ---\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # 1. Buat model gradien\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # 2. Rekam operasi gradien\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # 3. Hitung gradien\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    \n",
    "    # 4. Global Average Pooling (Rata-rata gradien)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # 5. Kalikan feature map dengan bobot gradien\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # 6. Normalisasi (ReLU & Scaling)\n",
    "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10) # Tambah epsilon biar gak error bagi 0\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def overlay_heatmap(img_path, heatmap, alpha=0.4, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        threshold (float): Nilai 0.0 - 1.0. \n",
    "                           Area heatmap di bawah nilai ini akan dibuang (dihitamkan).\n",
    "                           Berguna untuk menghilangkan noise/biru-biru di background.\n",
    "    \"\"\"\n",
    "    # 1. Load Gambar Asli\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, IMG_SIZE) # Pastikan ukuran sama (224, 224)\n",
    "    \n",
    "    # 2. Resize Heatmap agar sama persis dengan gambar asli\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # --- FITUR BARU: CLEAN NOISE (THRESHOLDING) ---\n",
    "    # Buang area yang panasnya kurang dari 30% (0.3)\n",
    "    # Ini membuat heatmap lebih fokus, tidak melebar ke mana-mana\n",
    "    heatmap[heatmap < threshold] = 0 \n",
    "    # ----------------------------------------------\n",
    "    \n",
    "    # 3. Ubah ke format 8-bit (0-255)\n",
    "    heatmap_uint8 = np.uint8(255 * heatmap)\n",
    "    \n",
    "    # 4. Beri Warna (JET: Biru=Dingin, Merah=Panas)\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # 5. Trik Visualisasi: \n",
    "    # Di colormap JET, nilai 0 (hitam) itu warnanya Biru Tua.\n",
    "    # Kita tidak mau background jadi biru semua.\n",
    "    # Jadi, area yang tadi kita buang (di bawah threshold), kita hitamkan kembali warnanya.\n",
    "    heatmap_colored[heatmap < threshold] = 0\n",
    "    \n",
    "    # 6. Gabungkan (Overlay)\n",
    "    superimposed_img = heatmap_colored * alpha + img\n",
    "    \n",
    "    # Pastikan tidak ada nilai pixel > 255\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype('uint8')\n",
    "    \n",
    "    return img, superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- PART 8: TEST PREDICTION (REVISED FOR EFFICIENTNET) ---\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Nama layer terakhir EfficientNetB0\n",
    "last_conv_layer_name = \"block5c_add\"\n",
    "\n",
    "# Ambil sample acak\n",
    "target_class = random.choice(['PNEUMONIA', 'NORMAL']) \n",
    "sample_dir = os.path.join(test_dir, target_class)\n",
    "sample_image = random.choice(os.listdir(sample_dir))\n",
    "img_path = os.path.join(sample_dir, sample_image)\n",
    "\n",
    "# --- BAGIAN PENTING (JANGAN SALAH DISINI) ---\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# HAPUS baris: img_array /= 255.0 (JANGAN PAKAI INI UNTUK EFFICIENTNET)\n",
    "# GANTI DENGAN INI:\n",
    "img_array = preprocess_input(img_array) \n",
    "# ---------------------------------------------\n",
    "\n",
    "# Prediksi\n",
    "preds = model.predict(img_array)\n",
    "score = preds[0][0]\n",
    "\n",
    "label_pred = \"PNEUMONIA\" if score > 0.5 else \"NORMAL\"\n",
    "confidence = score if score > 0.5 else 1 - score\n",
    "\n",
    "print(f\"File: {sample_image}\")\n",
    "print(f\"Ground Truth: {target_class}\")\n",
    "print(f\"Prediksi: {label_pred} ({confidence*100:.2f}%)\")\n",
    "\n",
    "# Grad-CAM\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=0)\n",
    "original_img, superimposed_img = overlay_heatmap(img_path, heatmap)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Asli: {target_class}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(heatmap, cmap='jet')\n",
    "plt.title(\"Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Prediksi: {label_pred}\\nConf: {confidence*100:.1f}%\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Validasi Text\n",
    "if label_pred == target_class:\n",
    "    print(\"âœ… PREDIKSI BENAR\")\n",
    "else:\n",
    "    print(\"âŒ PREDIKSI SALAH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- PART 9 (UPGRADE): APLIKASI WEB DENGAN SLIDER ---\n",
    "import gradio as gr\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Fungsi Prediksi menerima input tambahan: THRESHOLD\n",
    "def predict_image_interactive(image, threshold_slider):\n",
    "    if image is None:\n",
    "        return None, None\n",
    "        \n",
    "    # 1. Preprocessing\n",
    "    img_array = cv2.resize(image, IMG_SIZE)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # 2. Prediksi\n",
    "    preds = model.predict(img_array)\n",
    "    score = preds[0][0]\n",
    "    \n",
    "    if score > 0.5:\n",
    "        label = \"PNEUMONIA\"\n",
    "        conf = score\n",
    "    else:\n",
    "        label = \"NORMAL\"\n",
    "        conf = 1 - score\n",
    "        \n",
    "    # 3. Buat Grad-CAM\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=0)\n",
    "    \n",
    "    # Resize ke ukuran asli gambar input\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # --- PROSES SLIDER ---\n",
    "    # Gunakan nilai dari Slider Gradio untuk membersihkan heatmap\n",
    "    heatmap_clean = heatmap.copy()\n",
    "    heatmap_clean[heatmap_clean < threshold_slider] = 0 \n",
    "    # ---------------------\n",
    "    \n",
    "    # Pewarnaan\n",
    "    heatmap_uint8 = np.uint8(255 * heatmap_clean)\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Hapus background biru (kembalikan warna asli jika heatmap 0)\n",
    "    heatmap_colored[heatmap_clean < threshold_slider] = 0\n",
    "    \n",
    "    # Overlay\n",
    "    superimposed_img = heatmap_colored * 0.4 + image\n",
    "    \n",
    "    # Fix warna background yang hitam jadi gambar asli\n",
    "    mask = heatmap_clean < threshold_slider\n",
    "    superimposed_img[mask] = image[mask]\n",
    "    \n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype('uint8')\n",
    "    \n",
    "    return {label: float(conf), \"Lawan\": 1-float(conf)}, superimposed_img\n",
    "\n",
    "# Setup Antarmuka dengan Slider\n",
    "interface = gr.Interface(\n",
    "    fn=predict_image_interactive,\n",
    "    inputs=[\n",
    "        gr.Image(label=\"1. Upload X-Ray\"),\n",
    "        gr.Slider(minimum=0.0, maximum=1.0, value=0.3, label=\"2. Sensitivitas Heatmap (Geser untuk filter noise)\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Label(num_top_classes=2, label=\"Hasil Prediksi\"),\n",
    "        gr.Image(label=\"Visualisasi Lokasi Penyakit\")\n",
    "    ],\n",
    "    title=\"ðŸ¥ Advanced Pneumonia Detector\",\n",
    "    description=\"Analisis X-Ray berbasis EfficientNet-B0 dengan Grad-CAM Interaktif.\",\n",
    "    # Contoh gambar biar cepat tes (ambil dari folder test)\n",
    "    examples=[\n",
    "        [os.path.join(test_dir, 'PNEUMONIA', os.listdir(os.path.join(test_dir, 'PNEUMONIA'))[0]), 0.3],\n",
    "        [os.path.join(test_dir, 'NORMAL', os.listdir(os.path.join(test_dir, 'NORMAL'))[0]), 0.3]\n",
    "    ]\n",
    ")\n",
    "\n",
    "interface.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
